{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de rostros con openCV\n",
    "Este código esta basado en el código de Ramiz Raja (https://www.superdatascience.com/opencv-face-recognition/)\n",
    "\n",
    "En esta actividad se realiza reconocimiento de rostros. Se trabaja desde el entrenamiento de un modelo y se hace una predicción.\n",
    "\n",
    "Objetivos:\n",
    "1. Trabajar con funciones\n",
    "2. Detectar rostros (usando código de la actividad 3, detección de objetos)\n",
    "3. Leer la base de datos para entrenamiento\n",
    "4. Entrenar un modelo de clasificación\n",
    "5. Predecir a cual clase pertenece una imagen de entrada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar bibliotecas\n",
    "cv2 - OpenCV <br>\n",
    "os - Biblioteca para la lectura en directorios <br>\n",
    "numpy - Biblioteca para calculos numéricos <br>\n",
    "matplotlib - Biblioteca para graficación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etiquetas\n",
    "La base de datos estará etiquetada con carpetas con un número asigado. Sin embargo, cada número corresponde al nombre de una persona. Por ejemplo, la carpeta 1 puede contener fotografías de \"Pepe\", y la carpeta 2 tener las imágenes de \"Juan\". \n",
    "En el siguiente código se relaciona el número de la carpeta con el nombre real de la persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si las carpetas de la base de datos no empiezan numeradas en 0, entonces no se coloca un nombre en el índice 0 de la lista.\n",
    "subjects = [\"\", \"Pepe\", \"Juan\",\"José\",\"Miguel\",\"Toño\",\"Manuel\", \"Adrian\",\"Jesús\",\"Adolfo\"]\n",
    "#subjects = [\"\", \"1\", \"2\",\"3\",\"4\",\"5\",\"6\", \"7\",\"8\",\"9\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detectar rostros por medio de una función\n",
    "Este código contiene una parte del código de la actividad 3. \n",
    "\n",
    "Se define la función detect_face la cual recibe una imagen a color. <br>\n",
    "Posteriormente se convierte a grises.<br>\n",
    "Se lee el modelo clasificador *face_cascade* para detectar rostros frontales.<br>\n",
    "Se utiliza el modelo para detectar rostros en la imagen.<br>\n",
    "En dado caso que si se haya detectado un rostro se regresan las coordenadas del rectangulo en donde esta presente.<br>\n",
    "Si no se detecta un rostro no se regresa nada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "#Se convierte la imagen a escala de grises para ser usada por el detector\n",
    " gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "#Se lee el modelo de clasificador. \n",
    " face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    " \n",
    "#Se detectan rostros y se almacenan en la variable faces\n",
    " faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5);\n",
    " \n",
    "#Si no se detecta rostros se regresa la imagen original\n",
    " if (len(faces) == 0):\n",
    "  return None, None\n",
    " \n",
    "#Asusimos que solo tendremos un rostro\n",
    "#Se extra el área del rostro\n",
    " (x, y, w, h) = faces[0]\n",
    " \n",
    "#Se regresa únicamente la parte del rostro en la imagen\n",
    " return gray[y:y+w, x:x+h], faces[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de la base de datos y preparación de los datos para su entrenamiento\n",
    "Se define la función *prepare_training_data*. Esta función recibe la dirección que indica la ruta en donde se encuentran las imagenes de entrenamiento.\n",
    "\n",
    "En nuestro caso la ruta es \"./images/traindata\"\n",
    "\n",
    "Si observas la carpeta *traindata* te daras cuenta que esta ordenada de la siguiente manera: <br><br>\n",
    "\n",
    "traindata<br>\n",
    "\n",
    "|-------s1<br>\n",
    "|&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;          |--name1.jpg<br>\n",
    "|&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;          |--...<br>\n",
    "|&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;        |--nameN.jpg<br>\n",
    "|-------s2<br>\n",
    "|&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;          |--name1.jpg<br>\n",
    "|&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;          |--...<br>\n",
    "|&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;          |--nameN.jpg<br>\n",
    "\n",
    "\n",
    "data_folder_path tiene la ruta de las imagenes para entrenamiento.\n",
    "\n",
    "La función lee todas las carpetas contenidas (s1,s2,..,sn) y recorre dentro de cada carpeta buscando las imagenes. <br>\n",
    "Lee cada una de las imagenes usando *imread*. <br>\n",
    "Utiliza la función que declaramos en el input anterior *detect_face* para encontrar los rectangulos en donde estan el rostro.<br>\n",
    "Si existe un rostro en la imagen entonces se agrega a una lista de rostros y una lista que lleva seguimiento de las etiquetas *labels*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data_folder_path):\n",
    "    \n",
    "    #------Paso 1--------\n",
    "    #Obten las carpetas dentro de la ruta con las imagenes de entrenamiento. Cada carpeta corresponde a un sujeto.\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    \n",
    "    #Lista que contendrá las caras de todos los sujetos\n",
    "    faces = []\n",
    "    #Lista que contendrá las etiquetas de todos los sujetos\n",
    "    labels = []\n",
    "    \n",
    "    # Navegamos a traves de todas las carpetas y leemos las imágenes dentro de cada carpeta\n",
    "    for dir_name in dirs:\n",
    "        \n",
    "        # Las carpetas de cada sujeto empiezan con la letra 's', por lo tanto, cualquier carpeta que no empeza con s se ignora\n",
    "        if not dir_name.startswith(\"s\"):\n",
    "            continue;\n",
    "            \n",
    "        #------Pasp 2--------\n",
    "        # Se extra el número de etiqueta del sujeto a partir del nombre de la carpeta\n",
    "        # Recuerda el formato de la carpeta = slabel\n",
    "        # Removemos la letra \"s\" y nos quedamos solo con el número (Esto es la etiqueta)        \n",
    "        label = int(dir_name.replace(\"s\", \"\"))\n",
    "        \n",
    "        # Construimos la ruta hacia la carpeta que contiene las imagenes del sujeto actual\n",
    "        # Ejemplo de ruta = \"./images/traindata/s1\"\n",
    "        subject_dir_path = data_folder_path + \"/\" + dir_name\n",
    "        \n",
    "        #Se obtienen los nombres de las imagenes que estan dentro de cada carpeta\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "        \n",
    "        #------Paso 3--------\n",
    "        #Navegamos a través de cada imagen y la leemos\n",
    "        #detectamos los rostros y los agregamos a la lista\n",
    "        for image_name in subject_images_names:\n",
    "            \n",
    "            #Para ignorar archivos del sistema como .DS_Store\n",
    "            if image_name.startswith(\".\"):\n",
    "                continue;\n",
    "            \n",
    "            #se construye la ruta de la imagen que se va a leer\n",
    "            #Ejemplo de ruta = ./images/traindata/s1/1.jpg\n",
    "            image_path = subject_dir_path + \"/\" + image_name\n",
    "\n",
    "            #leer la imagen\n",
    "            image = cv2.imread(image_path)\n",
    "                      \n",
    "            #detección de rostro (usando la función definida arriba)\n",
    "            face, rect = detect_face(image)\n",
    "            \n",
    "            #------Paso 4--------\n",
    "            #Para propositos de este tutorial\n",
    "            #se ignoran los rostros que no son detectados\n",
    "            if face is not None:\n",
    "                #se agrega el rostro a la lista de rostros\n",
    "                faces.append(face)\n",
    "                #se agrega la etiqueta a la lista de etiquetas\n",
    "                labels.append(label)\n",
    "                \n",
    "    return faces, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se llama la función prepara datos\n",
    "A continuación, mandamos llamar a la función que acabamos de definir arriba. Le pasamos como parámetro la ruta en donde se encuentran nuestras imagenes de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando datos...\n",
      "Datos preparados\n",
      "Total faces:  60\n",
      "Total labels:  60\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparando datos...\")\n",
    "faces, labels = prepare_training_data(\"./images/traindata\")\n",
    "print(\"Datos preparados\")\n",
    "\n",
    "#Se imprie el total de rostros y etiquetas encontrados\n",
    "print(\"Total faces: \", len(faces))\n",
    "print(\"Total labels: \", len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconocimiento de rostros\n",
    "Primero se indica que algoritmo de reconocimiento se va a utilizar. En el siguiente código hay 3 opciones: <br>\n",
    "\n",
    "cv2.face.createLBPHFaceRecognizer<br>\n",
    "cv2.face.createEigenFaceRecognizer<br>\n",
    "cv2.face.createFisherFaceRecognizer<br>\n",
    "\n",
    "Puedes elegir cualquiera de ellos y comparar los resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.face' has no attribute 'createLBPHFaceRecognizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f6a8985f361e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#LBPH face recognizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mface_recognizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateLBPHFaceRecognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#face_recognizer = cv2.face.LBPHFaceRecognizer_create()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#EigenFaceRecognizer (Descomenta la siguiente linea si quieres utilizar este algoritmo)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.face' has no attribute 'createLBPHFaceRecognizer'"
     ]
    }
   ],
   "source": [
    "#LBPH face recognizer \n",
    "face_recognizer = cv2.face.createLBPHFaceRecognizer()\n",
    "#face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "#EigenFaceRecognizer (Descomenta la siguiente linea si quieres utilizar este algoritmo)\n",
    "#face_recognizer = cv2.face.createEigenFaceRecognizer()\n",
    "\n",
    "#FisherFaceRecognizer (Descomenta la siguiente linea si quieres utilizar este algoritmo)\n",
    "#face_recognizer = cv2.face.createFisherFaceRecognizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento\n",
    "En la siguiente linea de código se lleva a cabo el entrenamiento. Estamos utilizando el reconocer de rostro que elegimos y recibe como parámetros las lista con los rostros y las etiquetas que obtuvimos en la función de preparación de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train our face recognizer of our training faces\n",
    "face_recognizer.train(faces, np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dibujar las regiones con rostro\n",
    "Las siguiente funcion *draw_rectangle* nos ayudarán a dibujar un rectángulo sobre la imagen original en donde indique en que parte de la imagen se encuentra el rostro.\n",
    "\n",
    "La siguiente función *draw_text* nos va a colocar el nombre del sujeto que se predijo. Recuerda que arriba definimos los nombres de los sujetos en subjects = [\"\", \"Pepe\", \"Juan\",\"José\",\"Miguel\",\"Toño\",\"Manuel\", \"Adrian\",\"Jesús\",\"Adolfo\"].\n",
    "\n",
    "Si se predijo que una imagen pertenece a la clase con la etiqueta 2, entonces esta función va a colocar el nombre de \"Juan\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to draw rectangle on image \n",
    "#according to given (x, y) coordinates and \n",
    "#given width and heigh\n",
    "def draw_rectangle(img, rect):\n",
    "    (x, y, w, h) = rect\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "#function to draw text on give image starting from\n",
    "#passed (x, y) coordinates. \n",
    "def draw_text(img, text, x, y):\n",
    "    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción\n",
    "En la siguiente función se lleva a cabo la predicción.\n",
    "\n",
    "La función recibe una imagen de entranda, detecta el rostro usando la función *detect_face*. A continuación se utiliza la el reconocedor de rostros.\n",
    "\n",
    "Recuerda que el reconocedor de rostros *face_recognizer* ya fue entrenado. Esto quiere decir que ya tiene un modelo el cual solo va a evaluar. Se hace una predicción sobre un segmento de la imagen de prueba que solo contiene al rostro encontrado por la función *detect_face*.\n",
    "\n",
    "El reconocedor de rostro regresa la etiqueta *label* a la cual pertenece el sujeto. Gracias a la lista que definimos en un inicio (subjects = [\"\", \"Pepe\", \"Juan\",\"José\",\"Miguel\",\"Toño\",\"Manuel\", \"Adrian\",\"Jesús\",\"Adolfo\"]) podemos saber el nombre del sujeto.\n",
    "\n",
    "Lo siguiente consiste en dibujar un rectángulo sobre el rostro y el nombre del sujeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_img):\n",
    "    #Hacemos una copia para no modificar la imagen original\n",
    "    img = test_img.copy()\n",
    "    #Se detecta el rostro de la imagen\n",
    "    face, rect = detect_face(img)\n",
    "\n",
    "    #Se predice a que etiqueta pertenece la imagen usando el reconocedor\n",
    "    label= face_recognizer.predict(face)\n",
    "    #Se obtiene el nombre del sujeto dada la etiqueta predicha\n",
    "    label_text = subjects[label]\n",
    "    \n",
    "    #Se dibuja un rectangulo en donde esta contenido el rostro\n",
    "    draw_rectangle(img, rect)\n",
    "    #Se coloca el nombre de la persona\n",
    "    draw_text(img, label_text, rect[0], rect[1]-5)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se prueba todo el código haciendo 2 predicciones.\n",
    "En este caso probamos con 2 imagenes que provienen del sujeto 1 y 2 respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciendo imagenes...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1fb4f186f571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Predecir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpredicted_img1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mpredicted_img2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-34c7c440a7f5>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(test_img)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mface_recognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#Se obtiene el nombre del sujeto dada la etiqueta predicha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlabel_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubjects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#Se dibuja un rectangulo en donde esta contenido el rostro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "print(\"Prediciendo imagenes...\")\n",
    "\n",
    "#Cargar imagenes de prueba\n",
    "test_img1 = cv2.imread(\"./images/testdata/s1/9326871.15.jpg\")\n",
    "test_img2 = cv2.imread(\"./images/testdata/s2/9332898.16.jpg\")\n",
    "\n",
    "#Predecir\n",
    "predicted_img1 = predict(test_img1)\n",
    "predicted_img2 = predict(test_img2)\n",
    "print(\"Prediction complete\")\n",
    "\n",
    "\n",
    "#Desplegar imágenes\n",
    "plt.imshow(predicted_img1)\n",
    "plt.show()\n",
    "plt.imshow(predicted_img2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código se baso en: <br>\n",
    "https://www.superdatascience.com/opencv-face-recognition/ <br>\n",
    "https://github.com/informramiz/opencv-face-recognition-python/blob/master/OpenCV-Face-Recognition-Python.ipynb\n",
    "\n",
    "La base de datos es un extracto de la base de datos de \"Computer Vision Science Reserach Projects de Dr. Libor Spacek\", Collection of facial images: Faces94. <br>\n",
    "http://cswww.essex.ac.uk/mv/allfaces/faces94.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
